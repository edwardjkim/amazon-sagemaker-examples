{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SageMaker Models using XGBoost on SageMaker Managed Spot Training\n",
    "\n",
    "\n",
    "The XGBoost algorithm can be used as a built-in algorithm or as a framework such as TensorFlow. Using XGBoost as a framework provides more flexible than using it as a built-in algorithm as it enables more advanced scenarios that allow pre-processing and post-processing scripts to be incorporated into your training script. Using XGBoost as a built-in Amazon SageMaker algorithm is how you had to use the original XGBoost Release 0.72 version and nothing changes here except the version of XGBoost that you use.\n",
    "\n",
    "## Use XGBoost as a built-in algorithm\n",
    "\n",
    "The example here is almost the same as [Regression with Amazon SageMaker XGBoost algorithm](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb).\n",
    "\n",
    "This notebook tackles the exact same problem with the same solution, but it has been modified to be able to run using SageMaker Managed Spot infrastructure. SageMaker Managed Spot uses [EC2 Spot Instances](https://aws.amazon.com/ec2/spot/) to run Training at a lower cost.\n",
    "\n",
    "Please read the original notebook and try it out to gain an understanding of the ML use-case and how it is being solved. We will not delve into that here in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU awscli boto3 sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First setup variables and define functions\n",
    "\n",
    "Again, we won't go into detail explaining the code below, it has been lifted almost verbatim from [Regression with Amazon SageMaker XGBoost algorithm](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 123 ms, total: 1.18 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "prefix = 'sagemaker/DEMO-xgboost-regression'\n",
    "# customize to your bucket where you have stored the data\n",
    "bucket_path = 's3://{}'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the dataset\n",
    "\n",
    "Following methods split the data into train/test/validation datasets and upload files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 1 µs, total: 9 µs\n",
      "Wall time: 12.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import io\n",
    "import boto3\n",
    "import random\n",
    "\n",
    "def data_split(FILE_DATA, FILE_TRAIN, FILE_VALIDATION, FILE_TEST, PERCENT_TRAIN, PERCENT_VALIDATION, PERCENT_TEST):\n",
    "    data = [l for l in open(FILE_DATA, 'r')]\n",
    "    train_file = open(FILE_TRAIN, 'w')\n",
    "    valid_file = open(FILE_VALIDATION, 'w')\n",
    "    tests_file = open(FILE_TEST, 'w')\n",
    "\n",
    "    num_of_data = len(data)\n",
    "    num_train = int((PERCENT_TRAIN/100.0)*num_of_data)\n",
    "    num_valid = int((PERCENT_VALIDATION/100.0)*num_of_data)\n",
    "    num_tests = int((PERCENT_TEST/100.0)*num_of_data)\n",
    "\n",
    "    data_fractions = [num_train, num_valid, num_tests]\n",
    "    split_data = [[],[],[]]\n",
    "\n",
    "    rand_data_ind = 0\n",
    "\n",
    "    for split_ind, fraction in enumerate(data_fractions):\n",
    "        for i in range(fraction):\n",
    "            rand_data_ind = random.randint(0, len(data)-1)\n",
    "            split_data[split_ind].append(data[rand_data_ind])\n",
    "            data.pop(rand_data_ind)\n",
    "\n",
    "    for l in split_data[0]:\n",
    "        train_file.write(l)\n",
    "\n",
    "    for l in split_data[1]:\n",
    "        valid_file.write(l)\n",
    "\n",
    "    for l in split_data[2]:\n",
    "        tests_file.write(l)\n",
    "\n",
    "    train_file.close()\n",
    "    valid_file.close()\n",
    "    tests_file.close()\n",
    "\n",
    "def write_to_s3(fobj, bucket, key):\n",
    "    return boto3.Session(region_name=region).resource('s3').Bucket(bucket).Object(key).upload_fileobj(fobj)\n",
    "\n",
    "def upload_to_s3(bucket, channel, filename):\n",
    "    fobj=open(filename, 'rb')\n",
    "    key = prefix+'/'+channel\n",
    "    url = 's3://{}/{}/{}'.format(bucket, key, filename)\n",
    "    print('Writing to {}'.format(url))\n",
    "    write_to_s3(fobj, bucket, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to s3://sagemaker-us-west-2-959484541615/sagemaker/DEMO-xgboost-regression/train/abalone.train\n",
      "Writing to s3://sagemaker-us-west-2-959484541615/sagemaker/DEMO-xgboost-regression/validation/abalone.validation\n",
      "Writing to s3://sagemaker-us-west-2-959484541615/sagemaker/DEMO-xgboost-regression/test/abalone.test\n",
      "CPU times: user 180 ms, sys: 44.5 ms, total: 225 ms\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import urllib.request\n",
    "\n",
    "# Load the dataset\n",
    "FILE_DATA = 'abalone'\n",
    "urllib.request.urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/abalone\", FILE_DATA)\n",
    "\n",
    "#split the downloaded data into train/test/validation files\n",
    "FILE_TRAIN = 'abalone.train'\n",
    "FILE_VALIDATION = 'abalone.validation'\n",
    "FILE_TEST = 'abalone.test'\n",
    "PERCENT_TRAIN = 70\n",
    "PERCENT_VALIDATION = 15\n",
    "PERCENT_TEST = 15\n",
    "data_split(FILE_DATA, FILE_TRAIN, FILE_VALIDATION, FILE_TEST, PERCENT_TRAIN, PERCENT_VALIDATION, PERCENT_TEST)\n",
    "\n",
    "#upload the files to the S3 bucket\n",
    "upload_to_s3(bucket, 'train', FILE_TRAIN)\n",
    "upload_to_s3(bucket, 'validation', FILE_VALIDATION)\n",
    "upload_to_s3(bucket, 'test', FILE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the XGBoost model\n",
    "\n",
    "After setting training parameters, we kick off training, and poll for status until training is completed, which in this example, takes between 5 and 6 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost', '0.90-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-xgboost-regression-2019-09-27-05-09-28\n",
      "Checkpoint path: s3://sagemaker-us-west-2-959484541615/sagemaker/DEMO-xgboost-regression/checkpoints/DEMO-xgboost-regression-2019-09-27-05-09-28\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n",
      "CPU times: user 97.5 ms, sys: 10.3 ms, total: 108 ms\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = 'DEMO-xgboost-regression-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "train_use_spot_instances = True\n",
    "train_max_run = 3600\n",
    "train_max_wait = 7200 if train_use_spot_instances else None\n",
    "checkpoint_s3_uri = bucket_path + '/' + prefix + '/checkpoints/' + job_name if train_use_spot_instances else None\n",
    "print(\"Checkpoint path:\", checkpoint_s3_uri)\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": container,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": bucket_path + \"/\" + prefix + \"/single-xgboost\"\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.m4.4xlarge\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"silent\":\"0\",\n",
    "        \"objective\":\"reg:linear\",\n",
    "        \"num_round\":\"50\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": train_max_run,\n",
    "        \"MaxWaitTimeInSeconds\": train_max_wait\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\" + prefix + '/train',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\" + prefix + '/validation',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ],\n",
    "    \"EnableManagedSpotTraining\": train_use_spot_instances,\n",
    "    \"CheckpointConfig\": { \n",
    "        \"S3Uri\": checkpoint_s3_uri\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "client = boto3.client('sagemaker', region_name=region)\n",
    "client.create_training_job(**create_training_params)\n",
    "\n",
    "import time\n",
    "\n",
    "status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "while status !='Completed' and status!='Failed':\n",
    "    time.sleep(60)\n",
    "    status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingTimeInSeconds 40\n",
      "BillableTimeInSeconds 20\n"
     ]
    }
   ],
   "source": [
    "training_job_description = client.describe_training_job(TrainingJobName=job_name)\n",
    "print(\"TrainingTimeInSeconds\", training_job_description[\"TrainingTimeInSeconds\"])\n",
    "print(\"BillableTimeInSeconds\", training_job_description[\"BillableTimeInSeconds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use XGBoost as a framework\n",
    "\n",
    "For Managed Spot Training using XGBoost we need to configure three things:\n",
    "1. Enable the `train_use_spot_instances` constructor arg - a simple self-explanatory boolean.\n",
    "2. Set the `train_max_wait` constructor arg - this is an int arg representing the amount of time you are willing to wait for Spot infrastructure to become available. Some instance types are harder to get at Spot prices and you may have to wait longer. You are not charged for time spent waiting for Spot infrastructure to become available, you're only charged for actual compute time spent once Spot instances have been successfully procured.\n",
    "3. Setup a `checkpoint_s3_uri` constructor arg. This arg will tell SageMaker an S3 location where to save checkpoints (assuming your algorithm has been modified to save checkpoints periodically). While not strictly necessary checkpointing is highly recommended for Manage Spot Training jobs due to the fact that Spot instances can be interrupted with short notice and using checkpoints to resume from the last interruption ensures you don't lose any progress made before the interruption.\n",
    "\n",
    "Feel free to toggle the `train_use_spot_instances` variable to see the effect of running the same job using regular (a.k.a. \"On Demand\") infrastructure.\n",
    "\n",
    "Note that `train_max_wait` can be set if and only if `train_use_spot_instances` is enabled and **must** be greater than or equal to `train_max_run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: s3://sagemaker-us-west-2-959484541615/sagemaker/DEMO-xgboost-regression/checkpoints/482ac248-2a4e-404c-9c45-0c6bc09b73ae\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "train_use_spot_instances = True\n",
    "train_max_run = 3600\n",
    "train_max_wait = 7200 if train_use_spot_instances else None\n",
    "\n",
    "checkpoint_suffix = str(uuid.uuid4())\n",
    "\n",
    "if train_use_spot_instances:\n",
    "    checkpoint_s3_uri = bucket_path + '/' + prefix + '/checkpoints/' + checkpoint_suffix\n",
    "    print(\"Checkpoint path:\", checkpoint_s3_uri)\n",
    "else:\n",
    "    checkpoint_s3_uri = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-27 05:12:29 Starting - Starting the training job...\n",
      "2019-09-27 05:12:30 Starting - Launching requested ML instances......\n",
      "2019-09-27 05:13:56 Starting - Preparing the instances for training......\n",
      "2019-09-27 05:14:47 Downloading - Downloading input data...\n",
      "2019-09-27 05:15:25 Training - Training image download completed. Training in progress.\n",
      "2019-09-27 05:15:25 Uploading - Uploading generated training model\u001b[31mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:Module abalone does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: abalone\n",
      "  Building wheel for abalone (setup.py): started\n",
      "  Building wheel for abalone (setup.py): finished with status 'done'\n",
      "  Created wheel for abalone: filename=abalone-1.0.0-py2.py3-none-any.whl size=3753 sha256=6ffdeabbd2da0f27e3e9a701e5ec6e2e61faa5f8b1673b36073961f7635b75b0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tfhewo_5/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built abalone\u001b[0m\n",
      "\u001b[31mInstalling collected packages: abalone\u001b[0m\n",
      "\u001b[31mSuccessfully installed abalone-1.0.0\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"log_level\": 20,\n",
      "    \"user_entry_point\": \"abalone.py\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"libsvm\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"libsvm\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-959484541615/sagemaker-xgboost-2019-09-27-05-12-29-073/source/sourcedir.tar.gz\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"module_name\": \"abalone\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"is_master\": true,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"job_name\": \"sagemaker-xgboost-2019-09-27-05-12-29-073\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"silent\": \"0\",\n",
      "        \"subsample\": \"0.7\",\n",
      "        \"objective\": \"reg:linear\",\n",
      "        \"gamma\": \"4\",\n",
      "        \"num_round\": \"50\",\n",
      "        \"max_depth\": \"5\",\n",
      "        \"min_child_weight\": \"6\"\n",
      "    },\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"network_interface_name\": \"eth0\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=abalone\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:linear\",\"--silent\",\"0\",\"--subsample\",\"0.7\"]\u001b[0m\n",
      "\u001b[31mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:linear\",\"silent\":\"0\",\"subsample\":\"0.7\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"libsvm\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"libsvm\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2019-09-27-05-12-29-073\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-959484541615/sagemaker-xgboost-2019-09-27-05-12-29-073/source/sourcedir.tar.gz\",\"module_name\":\"abalone\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"abalone.py\"}\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-west-2-959484541615/sagemaker-xgboost-2019-09-27-05-12-29-073/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"libsvm\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"libsvm\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_HP_SILENT=0\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/:/usr/local/lib/python3.5/dist-packages/xgboost/dmlc-core/tracker:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=abalone.py\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:linear\",\"silent\":\"0\",\"subsample\":\"0.7\"}\u001b[0m\n",
      "\u001b[31mSM_HP_NUM_ROUND=50\u001b[0m\n",
      "\u001b[31mSM_HP_OBJECTIVE=reg:linear\u001b[0m\n",
      "\u001b[31mSM_HP_ETA=0.2\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m abalone --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:linear --silent 0 --subsample 0.7\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m[05:15:24] 2923x9 matrix with 23384 entries loaded from /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31m[05:15:24] 626x9 matrix with 5008 entries loaded from /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31m[05:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[31m[0]#011train-rmse:8.1022#011validation-rmse:8.13315\u001b[0m\n",
      "\u001b[31m[1]#011train-rmse:6.62011#011validation-rmse:6.69009\u001b[0m\n",
      "\u001b[31m[2]#011train-rmse:5.44573#011validation-rmse:5.54413\u001b[0m\n",
      "\u001b[31m[3]#011train-rmse:4.54751#011validation-rmse:4.67265\u001b[0m\n",
      "\u001b[31m[4]#011train-rmse:3.84479#011validation-rmse:4.00516\u001b[0m\n",
      "\u001b[31m[5]#011train-rmse:3.30138#011validation-rmse:3.50487\u001b[0m\n",
      "\u001b[31m[6]#011train-rmse:2.90287#011validation-rmse:3.12561\u001b[0m\n",
      "\u001b[31m[7]#011train-rmse:2.60497#011validation-rmse:2.8697\u001b[0m\n",
      "\u001b[31m[8]#011train-rmse:2.39075#011validation-rmse:2.68209\u001b[0m\n",
      "\u001b[31m[9]#011train-rmse:2.24158#011validation-rmse:2.54919\u001b[0m\n",
      "\u001b[31m[10]#011train-rmse:2.12162#011validation-rmse:2.44259\u001b[0m\n",
      "\u001b[31m[11]#011train-rmse:2.04309#011validation-rmse:2.37569\u001b[0m\n",
      "\u001b[31m[12]#011train-rmse:1.9852#011validation-rmse:2.33993\u001b[0m\n",
      "\u001b[31m[13]#011train-rmse:1.93846#011validation-rmse:2.30443\u001b[0m\n",
      "\u001b[31m[14]#011train-rmse:1.91032#011validation-rmse:2.28482\u001b[0m\n",
      "\u001b[31m[15]#011train-rmse:1.89237#011validation-rmse:2.27463\u001b[0m\n",
      "\u001b[31m[16]#011train-rmse:1.86885#011validation-rmse:2.26649\u001b[0m\n",
      "\u001b[31m[17]#011train-rmse:1.84224#011validation-rmse:2.25928\u001b[0m\n",
      "\u001b[31m[18]#011train-rmse:1.82761#011validation-rmse:2.25515\u001b[0m\n",
      "\u001b[31m[19]#011train-rmse:1.8144#011validation-rmse:2.25481\u001b[0m\n",
      "\u001b[31m[20]#011train-rmse:1.80181#011validation-rmse:2.25125\u001b[0m\n",
      "\u001b[31m[21]#011train-rmse:1.77552#011validation-rmse:2.2525\u001b[0m\n",
      "\u001b[31m[22]#011train-rmse:1.76976#011validation-rmse:2.24537\u001b[0m\n",
      "\u001b[31m[23]#011train-rmse:1.75256#011validation-rmse:2.23714\u001b[0m\n",
      "\u001b[31m[24]#011train-rmse:1.7409#011validation-rmse:2.23793\u001b[0m\n",
      "\u001b[31m[25]#011train-rmse:1.73878#011validation-rmse:2.23558\u001b[0m\n",
      "\u001b[31m[26]#011train-rmse:1.72508#011validation-rmse:2.23383\u001b[0m\n",
      "\u001b[31m[27]#011train-rmse:1.72024#011validation-rmse:2.22809\u001b[0m\n",
      "\u001b[31m[28]#011train-rmse:1.71296#011validation-rmse:2.22979\u001b[0m\n",
      "\u001b[31m[29]#011train-rmse:1.70584#011validation-rmse:2.23525\u001b[0m\n",
      "\u001b[31m[30]#011train-rmse:1.69652#011validation-rmse:2.23089\u001b[0m\n",
      "\u001b[31m[31]#011train-rmse:1.69105#011validation-rmse:2.23519\u001b[0m\n",
      "\u001b[31m[32]#011train-rmse:1.68049#011validation-rmse:2.2359\u001b[0m\n",
      "\u001b[31m[33]#011train-rmse:1.67452#011validation-rmse:2.2391\u001b[0m\n",
      "\u001b[31m[34]#011train-rmse:1.66231#011validation-rmse:2.24054\u001b[0m\n",
      "\u001b[31m[35]#011train-rmse:1.65897#011validation-rmse:2.24342\u001b[0m\n",
      "\u001b[31m[36]#011train-rmse:1.64688#011validation-rmse:2.24582\u001b[0m\n",
      "\u001b[31m[37]#011train-rmse:1.63728#011validation-rmse:2.24667\u001b[0m\n",
      "\u001b[31m[38]#011train-rmse:1.63431#011validation-rmse:2.24825\u001b[0m\n",
      "\u001b[31m[39]#011train-rmse:1.62309#011validation-rmse:2.25843\u001b[0m\n",
      "\u001b[31m[40]#011train-rmse:1.61672#011validation-rmse:2.25886\u001b[0m\n",
      "\u001b[31m[41]#011train-rmse:1.61227#011validation-rmse:2.26153\u001b[0m\n",
      "\u001b[31m[42]#011train-rmse:1.60487#011validation-rmse:2.26057\u001b[0m\n",
      "\u001b[31m[43]#011train-rmse:1.60196#011validation-rmse:2.25587\u001b[0m\n",
      "\u001b[31m[44]#011train-rmse:1.58986#011validation-rmse:2.25556\u001b[0m\n",
      "\u001b[31m[45]#011train-rmse:1.58597#011validation-rmse:2.25874\u001b[0m\n",
      "\u001b[31m[46]#011train-rmse:1.58372#011validation-rmse:2.26003\u001b[0m\n",
      "\u001b[31m[47]#011train-rmse:1.57533#011validation-rmse:2.25967\u001b[0m\n",
      "\u001b[31m[48]#011train-rmse:1.56801#011validation-rmse:2.25719\u001b[0m\n",
      "\u001b[31m[49]#011train-rmse:1.56499#011validation-rmse:2.25686\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-27 05:15:31 Completed - Training job completed\n",
      "Training seconds: 44\n",
      "Billable seconds: 18\n",
      "Managed Spot Training savings: 59.1%\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import s3_input\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\":\"5\",\n",
    "    \"eta\":\"0.2\",\n",
    "    \"gamma\":\"4\",\n",
    "    \"min_child_weight\":\"6\",\n",
    "    \"subsample\":\"0.7\",\n",
    "    \"silent\":\"0\",\n",
    "    \"objective\":\"reg:linear\",\n",
    "    \"num_round\":\"50\"\n",
    "}\n",
    "instance_type = \"ml.m4.4xlarge\"\n",
    "output_path = \"s3://{}/{}/{}/output\".format(bucket, prefix, \"single-xgboost\")\n",
    "content_type = \"libsvm\"\n",
    "\n",
    "xgb_script_mode_estimator = XGBoost(\n",
    "    entry_point=\"abalone.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    image_name=container,\n",
    "    role=role, \n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    framework_version=\"0.90-1\",\n",
    "    output_path=output_path,\n",
    "    train_use_spot_instances=train_use_spot_instances,\n",
    "    train_max_run=train_max_run,\n",
    "    train_max_wait=train_max_wait,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri)\n",
    "\n",
    "xgb_script_mode_estimator.fit(\n",
    "    {\n",
    "        \"train\": s3_input(\n",
    "            \"s3://{}/{}/{}\".format(bucket, prefix, \"train\"),\n",
    "            content_type=content_type\n",
    "        ),\n",
    "        \"validation\": s3_input(\n",
    "            \"s3://{}/{}/{}\".format(bucket, prefix, \"validation\"),\n",
    "            content_type=content_type\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savings\n",
    "Towards the end of the job you should see two lines of output printed:\n",
    "\n",
    "- `Training seconds: X` : This is the actual compute-time your training job spent\n",
    "- `Billable seconds: Y` : This is the time you will be billed for after Spot discounting is applied.\n",
    "\n",
    "If you enabled the `train_use_spot_instances` var then you should see a notable difference between `X` and `Y` signifying the cost savings you will get for having chosen Managed Spot Training. This should be reflected in an additional line:\n",
    "- `Managed Spot Training savings: (1-Y/X)*100 %`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
